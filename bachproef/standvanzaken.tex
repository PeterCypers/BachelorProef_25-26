\chapter{\IfLanguageName{dutch}{Stand van zaken}{State of the art}}%
\label{ch:stand-van-zaken}

% Tip: Begin elk hoofdstuk met een paragraaf inleiding die beschrijft hoe
% dit hoofdstuk past binnen het geheel van de bachelorproef. Geef in het
% bijzonder aan wat de link is met het vorige en volgende hoofdstuk.

% Pas na deze inleidende paragraaf komt de eerste sectiehoofding.
\section{Tips:}
Dit hoofdstuk bevat je literatuurstudie. De inhoud gaat verder op de inleiding, maar zal het onderwerp van de bachelorproef *diepgaand* uitspitten. De bedoeling is dat de lezer na lezing van dit hoofdstuk helemaal op de hoogte is van de huidige stand van zaken (state-of-the-art) in het onderzoeksdomein. Iemand die niet vertrouwd is met het onderwerp, weet nu voldoende om de rest van het verhaal te kunnen volgen, zonder dat die er nog andere informatie moet over opzoeken \autocite{Pollefliet2011}.

Je verwijst bij elke bewering die je doet, vakterm die je introduceert, enz.\ naar je bronnen. In \LaTeX{} kan dat met het commando \texttt{$\backslash${textcite\{\}}} of \texttt{$\backslash${autocite\{\}}}. Als argument van het commando geef je de ``sleutel'' van een ``record'' in een bibliografische databank in het Bib\LaTeX{}-formaat (een tekstbestand). Als je expliciet naar de auteur verwijst in de zin (narratieve referentie), gebruik je \texttt{$\backslash${}textcite\{\}}. Soms is de auteursnaam niet expliciet een onderdeel van de zin, dan gebruik je \texttt{$\backslash${}autocite\{\}} (referentie tussen haakjes). Dit gebruik je bv.~bij een citaat, of om in het bijschrift van een overgenomen afbeelding, broncode, tabel, enz. te verwijzen naar de bron. In de volgende paragraaf een voorbeeld van elk.

\textcite{Knuth1998} schreef een van de standaardwerken over sorteer- en zoekalgoritmen. Experten zijn het erover eens dat cloud computing een interessante opportuniteit vormen, zowel voor gebruikers als voor dienstverleners op vlak van informatietechnologie~\autocite{Creeger2009}.

Let er ook op: het \texttt{cite}-commando voor de punt, dus binnen de zin. Je verwijst meteen naar een bron in de eerste zin die erop gebaseerd is, dus niet pas op het einde van een paragraaf.

\section{AI \& LLMs}
\label{sec:aienllms}
%prominent note: de termen LLMs en AI gaan hierna door elkaar gebruikt worden, maar weet dat we het altijd zullen hebben over systemen die met drijfveer Large Language Modellen gebruiken, ook wanneer er over AI gesproken wordt
% note: keep this chapter verry theoretical (besides the sci-fi bit)
%intro


Het aanbod van generatieve AI tools, geïntegreerde chatbots, AI-agents, codeer-assistenten, tekstbewerkingstools, noem maar op, deze lijst blijft zich steeds verder uit te breiden. Men kan met AI verschillende soorten media produceren:
Genereren van tekst met ChatGPT of Google Gemini, beelden met DALL-E of Midjourney, video's met Synthesia of Grok Imagine en code met Copilot of AlphaCode.

\subsubsection{Het Magisch Sterretje}
We zien AI steeds meer in software geïntegreerd worden, AI is overal tegenwoordig, vaak zien we als teken van een AI integratie een knop met een aantal sterretjes wat de gebruiker signaleert dat hier achter de schermen AI in verwerkt zit.

Om een aantal voorbeelden te bespreken kijken we eerst naar Adobe Acrobat, hier hebben we een AI assistent waar we vragen aan kunnen stellen in verband met het document waaraan we werken, alsook een samenvatting genereren, mogelijk nog andere tekstverwerkende features, in outlook vinden we een "Summarize" knop boven een open email waarmee een samenvatting kan gegenereerd worden, er is ook een geïntegreerde Copilot embedded assistent waar bepaalde vragen aan kan gesteld worden. Naast de chat input waar de gebruiker vragen kan sturen naar de bot zien we ook een aantal vooraf gedefinieerde suggesties, namelijk: "Summarize this email", "Summarize and reply to this email", "Suggest my next step". In Windows notepad (of kladblok) hebben we Windows Copilot die de inhoud van het document kan samenvatten of in een andere toon (vb. van formeel naar grappig) zetten. Wanneer we in de browser zoeken naar iets krijgen we vaak een AI knop te zien waar we in plaats van de standaard zoeken een AI kunnen inzetten om te zoeken en direct de resultaten ook nog eens uit te leggen aan de gebruiker, waar eventueel nog bijkomende vragen aan kunnen gesteld worden, Google AI mode of Google Gemini output dat bovenaan de normale zoek-output gegenereerd wordt. \\

We hebben in WhatsApp onder het bedrijf Meta op het hoofdscherm al direct toegang tot een AI-chatbot: Meta AI die het model Llama 4 gebruikt, deze keer niet met sterretjes, maar een knop in de vorm van een meerkleurig donut. Meerkleurigheid is soms een alternatief voor de sterretjes, het moet vooral goed opvallen in de views lijkt wel het geval te zijn. Wanneer men een meerkleurig knop ziet op een website is dit vaak een teken dat hieronder een AI-systeem zit.

\subsection{AI en Windows}
%todo: source from Satya nadella https://news.microsoft.com/build-2025/
Er is een sterke push van Microsoft om meer AI in Windows te laten inbouwen. De huidige CEO van Microsoft, Satya Nadella, heeft de voorbije jaren tijdens de jaarlijkse Microsoft Keynote conferenties verschillende presentaties gegeven over de mogelijkheden van AI gebruik binnen Windows:

\begin{quote}
    "...AI has become so central to how we code, and that's why
    we're opensourcing copilot in VS-code..."
    - \autocite{Microsoft2025}
    
    "...This is the next big step forward, which is a full coding agent built right into github, taking copilot from being a pair-programmer to a peer programmer, you can assign issues to copilot, bugfixes, new features, code maintenance, and it'll complete these tasks autonomously..."
    - \autocite{Microsoft2025}
\end{quote}

Daarnaast binnen de Keynote van 2025 kwamen nog een aantal zaken aan bod: Azure AI foundary (in de cloud), Windows native MCP support.

Ook Microsoft M365 Copilot kwam veel ter sprake, deze brengt chat, zoeken, notebooks, create en agents allemaal samen, hier kan men "enterprise-grade agents" maken \autocite{Microsoft2025}. Dit is nu geïntegreerd in Windows Office, de M365 Copilot interface heeft namelijk die van de standaard MS Office vervangen. Deze heeft ook een ingebouwde chatbot, men kan ook in de browser de M365 Copilot chatbot aanspreken. \\

Nu binnen de MS Edge browser vinden we een Copilot knop waarmee we ook met een chatbot kunnen spreken en met context-kennis van de webpagina waarop we ons bevinden(wanneer dit is toegestaan in de privacy instellingen), dit is niet hetzelfde als M365 Copilot, dus we hebben hier een aantal verschillende versies:

\begin{itemize}
    \item \textbf{Microsoft M365 Copilot:} Geïntegreerd in Office en andere Windows-apps
    \item \textbf{Microsoft Copilot:} Geïntegreerd in Edge browser en Windows notepad
    \item  \textbf{Github Copilot Chat:} Een geïntegreerde chatbot en codeer-agent binnen Visual Studio Code(VSC). Microsoft is sinds 2018 ook eigenaar van Github.
\end{itemize}

Dit zijn maar een aantal van de AI integraties waar gebruikers mee in aanraking komen bij het dagelijks pc- en gsm-gebruik. Er is in een onderzoek gebleken dat men voor het oplossen van (academische)problemen evolueren naar het gebruik van AI in plaats van Google-zoeken, of zelfs nog meer een hybride van de twee, waar ze AI gebruiken, maar verifiëren met de klassieke zoekmachines \autocite{Sayeedi2025}.

Een graaf met verzamelde data van posts binnen een bepaalde periode op Stack Overflow van gebruiker einpoklum \ref{fig:stackoverflowpostsdecline} deed recent de ronde op sociale media. Als we het aantal gebruikers kunnen afleiden uit het aantal posts op het platvorm dan kunnen we concluderen dat mensen deze steeds minder bezoeken als er een moeilijk op te lossen probleem zich voor doet in de code en eerder grijpt naar een AI-chatbot of codeer-agent(assistent). Of mogelijks een combinatie van de twee, de graaf toont alleszins een dalende trend in het gebruik van Stack Overflow aan.


%https://meta.stackoverflow.com/questions/437921/how-does-the-continued-decline-in-posts-since-may-25-influence-our-interpretati

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{stackoverflowposts.png}
    \caption[Stackoverflow posts grafiek]{\label{fig:stackoverflowpostsdecline}Het aantal posts op StackOverflow vanaf de website opstart tot op heden \autocite{einpoklum2026}.}
\end{figure}

%todo: make sure to correctly reference figures (possible the ref needs to be in the figure explenation - see Research Methods)


\section{AI van Science-Fiction naar Werkelijkheid}
\label{sec:aivanscience-fictionnaarwerkelijkheid}
% add the bit I wrote earlier


\section{AI}
% At it's core AI can be described as: "The simulation of human intelligence by machines" -> find source
%Learning from massive amounts of data(see also:scraping) through 'training'
Het aanbod in AI tools en chatbots, AI-agents  zijn de laatste jaren 


\subsection{Discriminative AI}
Volgens \autocite{IBM2026} maakt deze soort AI een onderscheid tussen verschillende klassen van data, elke nieuwe datapunt wordt gelabeld met een klasse, wanneer een nieuw datapunt wordt toegevoegd zal het model proberen voorspellen aan welke kant van de "decision-boundary" het nieuwe datapunt valt. vb. foto van een Kat of een Hond. Achterliggend worden geavanceerde algoritmes gebruikt om:
\begin{enumerate}
    \item verschillen te bepalen
    \item te classificeren
    \item patronen te identificeren
    \item conclusies te trekken
\end{enumerate}

Een goede use-case voor dit soort AI is het filteren van spam e-mails. Deze modellen zijn uitermate geschikt om te vragen: Is dit A, of is dit B.

De modellen kunnen geen context begrijpen of nieuwe content genereren gebaseerd op hun training data.

\subsection{Generative AI}
%refer to course1 -> all input text, so first transforming inputs via speechtotext, img to base64, natural language processing

Volgens \autocite{IBM2026} kunnen generatieve modellen de onderliggende distributie van de trainingsdata vastleggen en hiermee nieuwe datapunten genereren. Ze krijgen data als input in een bepaalde vorm onder anderen tekst, afbeelding of video en vormen dit om naar output data in dat hetzelfde kan zijn als de input, maar ook een andere vorm van data kan zijn.

Generatieve AI kan ingezet worden om van tekst input een tekst output te genereren (text-to-text) of van een tekst input naar een audio output te gaan (text-to-speech).
Zo zijn er verscheidene mogelijkheden om generatieve AI te gebruiken om met allerlei soorten input data een nieuwe output te laten genereren als bepaald type van data.

Discriminative en Generative AI modellen worden gemaakt door deep learning technieken toe te passen. Deep learning is het trainen van artificiële neuraal netwerken(verzameling neuronen gemodelleerd op het menselijk brein) op ontzettend grote hoeveelheden data

De creativiteit van AI generatie komt van: GANs (Generative Adversarial Networks) / VAEs (Variational Auto-encoders) / Transformers / Diffusion models. Deze hebben de evolutie van AI versneld en geleid tot het ontstaan van foundation modellen, deze zijn AI modellen met heel algemene toepassingsmogelijkheden. Deze kunnen aangepast worden met fine-tuning om te dienen als tools voor specifieke use-cases. LLMs (Large Language Models) maken deel uit van foundation modellen \autocite{Bommasani2021}.

\section{LLMs}

In 2018 kwam OpenAI uit de proppen met een op Transformers gebaseerde LLM genaamd GPT 1 (Generative Pretrained Transformer 1). Hiervóór had Google al onderzoek gedaan naar de Transformers architectuur in \autocite{Vaswani2017}. \\
OpenAI bouwt hierop verder met hun onderzoek waarin beschrijven staat hoe ze hebben kunnen overschakelen op unsupervised pre-training en daarna supervised fine-tuning wat de trainingsproces enorm optimaliseerde en het mogelijk maakte om heel grote modellen te trainen \autocite{Radford2018}. \\

Tot op dat punt werden NLP modellen vooral getrained met supervised learning, een machine learning techniek, gebruikmakend van een grote hoeveelheid manueel gelabelde data wat ontzettend tijdrovend en duur was \autocite{Radford2018}. \\

De online chat interface die we kennen als ChatGPT werd als commercieel product op de wereld losgelaten in november 2022:

\begin{quote}
    "We’ve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject inappropriate requests."
    - \autocite{OpenAI2022}
\end{quote}

\begin{quote}
    "ChatGPT is fine-tuned from a model in the GPT‑3.5 series, which finished training in early 2022."
    - \autocite{OpenAI2022}
\end{quote}


\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{OpenAI_ChatGPT_12-2022.png}
    \caption[ChatGPT Interface december 2022]{\label{fig:earlychatgptview}Dit was de ChatGPT interface op 9-12-2022.}
\end{figure}

Het Trainingsmethode van ChatGPT ging als volgt:

\begin{quote}
"We trained this model using Reinforcement Learning from Human Feedback (RLHF), using the same methods as InstructGPT⁠, but with slight differences in the data collection setup. We trained an initial model using supervised fine-tuning: human AI trainers provided conversations in which they played both sides—the user and an AI assistant. We gave the trainers access to model-written suggestions to help them compose their responses. We mixed this new dialogue dataset with the InstructGPT dataset, which we transformed into a dialogue format.
- \autocite{OpenAI2022}

To create a reward model for reinforcement learning, we needed to collect comparison data, which consisted of two or more model responses ranked by quality. To collect this data, we took conversations that AI trainers had with the chatbot. We randomly selected a model-written message, sampled several alternative completions, and had AI trainers rank them. Using these reward models, we can fine-tune the model using Proximal Policy Optimization⁠. We performed several iterations of this process."
- \autocite{OpenAI2022}
\end{quote}

Het is volgens OpenAI een iteratief proces waarbij ze van plan zijn om steeds betere modellen uit te rollen.

Een gedetailleerd visueel uitwerking van de interne werking van een LLM kan men hier bekijken: \footnote{\href{https://bbycroft.net/llm}{https://bbycroft.net/llm}}
Dit project van Brendan Bycroft visualiseert de structuur van bepaalde GPT-modellen bespreekt stap voor stap wat er in de verschillende lagen gebeurt. \\

LLMs zijn getrained op zeer grote datasets of ruwe data verzameld op webniveau \autocite{Bommasani2021}. Voor de mogelijke fouten dat LLMs kunnen maken zie: 
%todo: reference forward to Risicos van AI

%We delven niet te ver in details,
maar het is zinvol om enkele kenmerken van LLMs te bespreken.
%todo: more kenmerken of LLMs

%ch.1 video NLP

%next word prediction


%section Tokens:
%https://platform.openai.com/tokenizer


%todo: in this chapter explaining LLMs, Tokens & Context window, parameters, Size, ETC

%todo: check output of ollama show gemma3 -> explain things like 

%todo: explain difference bewteen AI and machine learning?

%todo: snelheid van llms gemeten in tokens/s https://www.reddit.com/r/LocalLLaMA/comments/1miggb2/what_hardware_to_run_gptoss120b/

%todo: chapter about Tokens \& Pricing(can mention pricing, but pricing gets it's own chapter in Marktonderzoek) -expected in chapter to mention differences by provider and measure in per million tokens -> I have an image somewhere showing this for gpt or claude

%todo: put in chapter about context window
%https://www.ibm.com/think/topics/context-window ()in refs as Bergmann)
Eerst even wat uitleg over de \textit{context window}. Volgens \todo{reference  Bergmann} kan dit gezien worden als het werkgeheugen van een LLM. Dit bepaalt hoe lang het gesprek kan lopen (meerdere prompts) en bepaalt ook externe resources de LLM tegelijk can verwerken (documenten, codefragmenten, afbeeldingen, etc.).
Alles dat gebruikt werd bij een bepaalde sessie met een LLM komt in de context window terecht, alle voorgaande vragen(prompts) en gedeelde resources worden in rekening genomen wanneer de LLM een response terug geeft aan de gebruiker.


%todo: intro in chapter: Tokens, same reference as context window: Bergmann
Alle input wordt omgezet naar tokens die de LLM gebruikt om voorspellingen te maken die leiden tot het meest waardevolle antwoord. Wanneer de totale opgebouwde tokens de context-venster overschrijden dan moet de LLM samenvattingen beginnen maken ... \todo{schrijf verder, reference: Bergmann}

%todo: ubiquitousness / of AI commercial popularity of AI / integration of AI in much software / focus on integration (windows sundar pachai: interview he says something about going all in on AI - ??% of new windows-code is AI or vibe coded -> find sources and references for sundar pachai's statements and the ??% vibecoded windows 11)

%todo:


\subsection{Multimodal LLMs}

Vanaf dit punt zullen de termen LLM en AI tussen elkaar uitgewisseld worden want als er wordt gesproken over het gebruik van één van beiden zal het altijd gaan over het inzetten van een Large Language Model met AI eerder als spreektaal.

\section{Prompting}
\subsection{Prompt Engineering}
% prompting techniques guide ref: https://www.promptingguide.ai/techniques
% THERE IS A DIFFERENCE BETWEEN THIS AND "SOORTEN PROMPTS" templates & other things vs zero/1shot/few-shot/COT/instruction tuning/ICL in context learning

\subsection{In-context learning}
%look more into what this is exactly

\subsection{Prompt Templates}




\section{Agentic AI}

\subsection{Tool gebruik}

\section{RAG}
% large section... RAG(Retrieval Augmented Generation)
% explain the different steps that make up RAG, at least 1 figure that shows the entire process
%explain some various applications/use-cases for rag
%forwards reference to vergel.-studie demo
%subsubsection for each part of RAG, including Vector Databases

% j J
%intro:
Een probleem dat bestaat bij AI is dat er een beperkt context is dat deze kan
%todo: rewrite to NL, dient als introductie
Big Picture Thinking Problem (DRY/maintainability/existing functions/codebase-context understanding/focus on solving everything in the AI-output)
AI agents have limited context understanding, one of the problems that can arise from the use of AI is that it doesn’t have big picture, project-wide scope of understanding, it doesn’t know that an interface exists to call somewhere else in the project. 

It will always be a problem because AI will always have some limit to how much additional context it can be given when prompted, it may increase if models continue to get stronger, but there will always be some limit.

There are areas where some progress has been made in solving this problem, like cursor and claude code which use …* to get project-wide context

*: %todo: look into what they exactly did, it likely predates RAG
%*RAG? -> todo: find out/look up, etc

RAG (Retrieval Augmented Generation) is ... %todo: + reference
dit voorziet LLMs van extra context dat ze kunnen gebruiken om betere responses te genereren.

\subsection{Vector Databases}
% FAISS and ChromaDB
\section{ReACT Agent}

\section{Multi-Agent Workflow}
%forwards reference to vergel.-studie demo

\section{Model Context Protocol(todo)}
%postmanmcp
