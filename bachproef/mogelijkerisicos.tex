%%=============================================================================
%% Risicos
%%=============================================================================
\chapter{\IfLanguageName{dutch}{Risico's van AI gebruik}{Risks of using AI}}%
\label{ch:risicosvanaigebruik}

\begin{comment}
    DREIGINGEN INHERENT IN LLMs
    LLMs als een snapshot in de tijd:
    -------------------------------
    De kennis van een LLM wordt bepaald door de data waarop die is
    getrained. Dit is een grote verzameling van informatie vanuit
    verschillende bronnen (vaak internet scraping van bepaalde websites)
    stack overflow, reddit, etc.
    
    De relevantie van deze data neemt onmiddelijk af vanaf het moment
    dat deze AI-versie is gelanceerd, stel dat je het model gpt-2 
    wil gebruiken en een vraag stelt over wat er in de wereld is gebeurd
    na 2020, deze zal hier niet op kunnen antwoorden omdat het model
    is uitgekomen in 2019 en is gelimiteerd in kennis tot informatie
    voor zijn uiteindelijke lancering op de markt.
    
    Relevante kennis van LLMs
    --------------------------
    Stel dat men de laatste niewe ontwikkelingen wilt gebruiken in een
    bepaalde programmeer taal, dan is het minder zinvol om een oud
    LLM te gebruiken die nog geen kennis heeft van deze taal.
    
    Er moeten steeds nieuwe versies van LLMs uitgebracht worden
    omdat de data waarop ze getrained zijn vervalt.
    
    Moest men de LLM willen gebruiken als een efficiente pair-programmer
    of assistent is het zinvol dat die op zijn minst de code waarmee
    er gewerkt wordt kent en geen code oplossing aanbeveelt dat
    verouderd en totaal niet zo efficient is als de recentere
    oplossingen die tot stand zij gekomen.
    
    De qualiteit van trainings data is ook een aspect dat hoort bij
    het trainen van nieuwe model-versies. Het is mogelijk om een 
    LLm te vergiftigen met slechte data, stel dat men de LLM over
    X-aantal iteraties enkel op zijn eigen kennis traint... 
    (terzijde? zinvol? zoek info om het juist uit te kunnen leggen)
    
    Mogelijke toekomstige scenario:(find a better way to word)
    Het is zeker een onderwerp voor discussie, wanneer men vooral AI
    gebruikt, stel dat deze onze input niet zouden gebruiken om op te
    trainen, men gaat steeds meer en meer AI gebruiken om vragen te
    beantwoorden, websites waar men vroeger vragen stelde (stackoverflow)
    (ref the diagram that shows it's user count is at an all time low)
    hier gaat men minder en minder naar toe, de AI zou weinig zinvolle
    kennis hebben van alle mogelijke kennis in de wereld omdat er geen
    bronnen meer zouden zijn om deze kennis te halen (met webscraping)
    
    ---------
    (different topic: AI \& code-plagiaat \& lopende rechtzaken)
    (is het ok om zomaar de code van iemand anders te gebruiken, 
    vroeger had je er zelf naar op zoek moeten gaan, nu sugereert de
    AI dit gewoon...)(copy-pasten van oplossingen uit stackoverflow is
    niet hetzelfde, dit was met opzet gedeeld)(moderne LLMs zijn mogelijks
    getrained op github code -> find proof)
    ---------
    
    (decide what needs verification + references/sources)
    
    -------
    
    security and privacy (write something on this topic, it's a problem inherent to LLMs & AI-providers/services/companies)
    
\end{comment}

\begin{comment}
    DREIGINGEN VAN BUITENAF:
    - Snelle veranderingen -> investering in up-to-date houden van je AI-systemen
    agents / multi-agent systems / AI-providers and services / continu testen & benchmarking van je AI
    regelmatig nood voor het upgraden naar nieuwere modellen -> zorgen dat deze mee evolueren met de continu veranderende tech wereld 
    alsook de evoluties in je codeer-taal
    
    - Volatiele markt:
    
    - Chips (NVidia)
    
    - AI-providers die in problemen komen met rechtzaken (OpenAI)
    
    - Waar komt het geld vandaan?
    
    - Het verzamelen van gebruikers-data (gevoelige gegevens/bedrijfsgegevens/bedr.-code)
\end{comment}


